{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Reviews Dataset\n",
    "\n",
    "The IMDB Review dataset contains movie reviews along with associated binary sentiment polarity labels.The main dataset contains 50,000 reviews split evenly between a train and test set (25,000 each). The distribution of positive and negative labels are balanced.\n",
    "\n",
    "In the entire dataset, no more than 30 movie reviews are allowed for the same movie. This is because reviews for the same movie tend to have correlation. Further, the train and test sets contain a disjoint set of movies, so no significant performance is obtained by memorizing movie-unique terms and their associated with observed labels.\n",
    "\n",
    "For the train/test set a negative review has a score <= 4 out of 10 and a positive review has a score >= 7 out of 10. Reviews with a more neutral score were not included in the dataset.\n",
    "\n",
    "Link: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "The objective is to perform a sentiment analysis on this dataset using various machine learning models\n",
    "\n",
    "\n",
    "## Loading the IMDB Dataset\n",
    "\n",
    "Format the dataset into lists of strings and review a few examples of positive and negative reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries (general)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unpacked in aclImdb Folder\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import wget\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "#DownLoad IMDB Data to your working path from the link below\n",
    "URL = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "#Downloads the file to your current working directory\n",
    "#May need to install the wget package: conda install -c conda-forge python-wget\n",
    "if not os.path.exists('aclImdb_v1.tar.gz'):\n",
    "    wget.download(URL)\n",
    "\n",
    "#The file downloaded is in the aclImdb_v1.tar.gz file\n",
    "tar = tarfile.open(\"aclImdb_v1.tar.gz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "print(\"Dataset unpacked in aclImdb Folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the original text files from the aclImdb folder and write the contents to a new text file.\n",
    "#The end result is 4 text files for positive and negative reviews in seperate train and test datasets\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "#Make a folder for the new text files\n",
    "if not os.path.exists('IMDB_Data'):\n",
    "    os.mkdir(\"IMDB_Data\")\n",
    "\n",
    "read_files = glob.glob(os.path.join('aclImdb/train/pos',\"*.txt\"))\n",
    "\n",
    "with open('IMDB_Data/pos_train.txt','wb') as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f,'rb') as infile:\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "        outfile.write(b\"\\n\")\n",
    "        \n",
    "read_files = glob.glob(os.path.join('aclImdb/train/neg',\"*.txt\"))\n",
    "\n",
    "with open('IMDB_Data/neg_train.txt','wb') as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f,'rb') as infile:\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "        outfile.write(b\"\\n\")\n",
    "        \n",
    "read_files = glob.glob(os.path.join('aclImdb/test/pos',\"*.txt\"))\n",
    "\n",
    "with open('IMDB_Data/pos_test.txt','wb') as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f,'rb') as infile:\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "        outfile.write(b\"\\n\")\n",
    "        \n",
    "read_files = glob.glob(os.path.join('aclImdb/test/neg',\"*.txt\"))\n",
    "\n",
    "with open('IMDB_Data/neg_test.txt','wb') as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f,'rb') as infile:\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "        outfile.write(b\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the contents of the text files into a list of strings\n",
    "reviews_train_pos = []\n",
    "for line in open('IMDB_Data/pos_train.txt', 'r', encoding = \"utf8\"):\n",
    "    reviews_train_pos.append(line.strip())\n",
    "    \n",
    "reviews_train_neg = []\n",
    "for line in open('IMDB_Data/neg_train.txt', 'r', encoding = \"utf8\"):\n",
    "    reviews_train_neg.append(line.strip())\n",
    "    \n",
    "reviews_test_pos = []\n",
    "for line in open('IMDB_Data/pos_test.txt', 'r', encoding = \"utf8\"):\n",
    "    reviews_test_pos.append(line.strip())\n",
    "    \n",
    "reviews_test_neg = []\n",
    "for line in open('IMDB_Data/neg_test.txt', 'r', encoding = \"utf8\"):\n",
    "    reviews_test_neg.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n",
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_train_pos))\n",
    "print(len(reviews_train_neg))\n",
    "print(len(reviews_test_pos))\n",
    "print(len(reviews_test_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positive Review Example\n",
    "reviews_train_pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I\\'m a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another Positive Review Example\n",
    "reviews_train_pos[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative Review Example\n",
    "reviews_train_neg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another Negative Review Example\n",
    "reviews_train_neg[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Cleaning the Text Data\n",
    "\n",
    "As seen above, the original reviews are quite messy and need to be cleaned in order to help the machine learning models. This includes removing capital letters, removing punctuation, and any other uneccessary characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "replace_no_space = re.compile(\"[.;:!\\'?_,\\\"()\\[\\]]\")\n",
    "replace_with_space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [replace_no_space.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [replace_with_space.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_pos_clean1 = preprocess_reviews(reviews_train_pos)\n",
    "reviews_train_neg_clean1 = preprocess_reviews(reviews_train_neg)\n",
    "reviews_test_pos_clean1 = preprocess_reviews(reviews_test_pos)\n",
    "reviews_test_neg_clean1 = preprocess_reviews(reviews_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The same postive review example after being cleaned\n",
    "reviews_train_pos_clean1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story of a man who has unnatural feelings for a pig starts out with a opening scene that is a terrific example of absurd comedy a formal orchestra audience is turned into an insane violent mob by the crazy chantings of its singers unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting even those from the era should be turned off the cryptic dialogue would make shakespeare seem easy to a third grader on a technical level its better than you might think with some good cinematography by future great vilmos zsigmond future stars sally kirkland and frederic forrest can be seen briefly'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The same negative review example after cleaning\n",
    "reviews_train_neg_clean1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Further Text Processing: Removing Stop Words and Normalization\n",
    "\n",
    "Other methods of cleaning the data that can change the model performance include removing stop_words or Normalization (Stemming or Lematization)\n",
    "\n",
    "Stop words are very common words such as 'in', 'of', 'a', 'at', or 'the' that usually don't provide any useful information to the text classifier\n",
    "\n",
    "Normalization (Stemming or Lematization) is a common next step in text preprocessing that converts all the different forms of a certain word into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\patri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\patri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "#Stemming\n",
    "def stemming_text(text_data):\n",
    "    stem = PorterStemmer()\n",
    "    return [' '.join([stem.stem(word) for word in review.split()]) for review in text_data]\n",
    "\n",
    "\n",
    "#Lemmatization\n",
    "def lemmatize_text(text_data):\n",
    "    lem = WordNetLemmatizer()\n",
    "    return [' '.join([lem.lemmatize(word) for word in review.split()]) for review in text_data]\n",
    "\n",
    "    \n",
    "#Alternatively there is an easier way to remove stop words by using the stop_words argument with any of scikit-learn’s ‘Vectorizer’ classes\n",
    "#Removing stop words often (but not always) improves the model accuracy   \n",
    "#Need to create the list of stop_words (usually more effective than general lists)\n",
    "#stop_words=['in','of','at','a','the']\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_pos_clean = lemmatize_text(reviews_train_pos_clean1)\n",
    "reviews_train_neg_clean = lemmatize_text(reviews_train_neg_clean1)\n",
    "reviews_test_pos_clean = lemmatize_text(reviews_test_pos_clean1)\n",
    "reviews_test_neg_clean = lemmatize_text(reviews_test_neg_clean1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy it ran at the same time a some other program about school life such a teacher my 35 year in the teaching profession lead me to believe that bromwell high satire is much closer to reality than is teacher the scramble to survive financially the insightful student who can see right through their pathetic teacher pomp the pettiness of the whole situation all remind me of the school i knew and their student when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector im here to sack one of your teacher student welcome to bromwell high i expect that many adult of my age think that bromwell high is far fetched what a pity that it isnt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_pos_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story of a man who ha unnatural feeling for a pig start out with a opening scene that is a terrific example of absurd comedy a formal orchestra audience is turned into an insane violent mob by the crazy chanting of it singer unfortunately it stay absurd the whole time with no general narrative eventually making it just too off putting even those from the era should be turned off the cryptic dialogue would make shakespeare seem easy to a third grader on a technical level it better than you might think with some good cinematography by future great vilmos zsigmond future star sally kirkland and frederic forrest can be seen briefly'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_neg_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data Sets for Feature Vectorization and Classification Models\n",
    "\n",
    "With these datasets the positve and negative results will be combined and the data needs to be shuffled since the positive and negative data is grouped together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "#Combine all the positive and negative reviews to end up with one training set and one testing set of 25,000 samples each\n",
    "reviews_train = []\n",
    "reviews_train_combined = reviews_train_pos_clean + reviews_train_neg_clean\n",
    "print(len(reviews_train_combined))\n",
    "\n",
    "reviews_test = []\n",
    "reviews_test_combined = reviews_test_pos_clean + reviews_test_neg_clean\n",
    "print(len(reviews_test_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te of the storm country is possibly the best movie of all of mary pickford film at two hour it wa quite long for a 1922 silent film yet continues to hold your interest some 80 year after it wa filmed mary give one of her finest performance at time the role seems like a greatest hit performance with bit of mary the innocent mary the little devil mary the little mother mary the spitfire mary the romantic heroine etc characteristic that often were used throughout a single film in the past the movie is surprisingly frank about one supporting character illegitimate child for 1922 and at one point our little mary is thought the unwed mother in question if the academy award had been around in 1922 no doubt the best actress oscar for the year would have been mary\n",
      "1\n",
      "this movie wa a low point for both jason robards and sam peckinpah major plot point are taken directly from sergio leone masterpiece once upon a time in the west released two year earlier and also featuring robards a man find a watering hole is found in the desert being the only water for many mile in every direction he plan to build a station around the hole and to ensure there a love interest he fall in love with a prostitute to this add an intemperate preacher bad music silly fast action shot even sillier t&a shot and there you go there is little question why it failed at the box office the real question is how did it make it that far\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Shuffle\n",
    "import random\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "c = list(zip(reviews_train_combined, target))\n",
    "random.shuffle(c)\n",
    "reviews_train, y_train = zip(*c)\n",
    "\n",
    "print(reviews_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "b = list(zip(reviews_test_combined, target))\n",
    "random.shuffle(b)\n",
    "reviews_test, y_test = zip(*b)\n",
    "\n",
    "print(reviews_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectorization (Count Vectorizer and TF-IDF)\n",
    "\n",
    "### Can use either the Unigram Vectorization Features, Bigram Vectorization Features, or TF-IDF Features in the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 83709)\n",
      "  (0, 73231)\t1\n",
      "  (0, 70744)\t1\n",
      "  (0, 16969)\t1\n",
      "  (0, 57561)\t1\n",
      "  (0, 8266)\t2\n",
      "  (0, 49626)\t2\n",
      "  (0, 46325)\t9\n",
      "  (0, 56285)\t1\n",
      "  (0, 27432)\t3\n",
      "  (0, 76757)\t1\n",
      "  (0, 35638)\t1\n",
      "  (0, 80001)\t2\n",
      "  (0, 59609)\t1\n",
      "  (0, 44171)\t1\n",
      "  (0, 397)\t3\n",
      "  (0, 67421)\t1\n",
      "  (0, 82964)\t1\n",
      "  (0, 16340)\t1\n",
      "  (0, 35080)\t1\n",
      "  (0, 38016)\t1\n",
      "  (0, 1348)\t1\n",
      "  (0, 82844)\t2\n",
      "  (0, 27471)\t1\n",
      "  (0, 30917)\t1\n",
      "  (0, 53067)\t3\n",
      "  :\t:\n",
      "  (24998, 78739)\t1\n",
      "  (24998, 64676)\t2\n",
      "  (24999, 49626)\t2\n",
      "  (24999, 80001)\t2\n",
      "  (24999, 57090)\t1\n",
      "  (24999, 49954)\t1\n",
      "  (24999, 31395)\t1\n",
      "  (24999, 72789)\t1\n",
      "  (24999, 38618)\t1\n",
      "  (24999, 64578)\t1\n",
      "  (24999, 82448)\t1\n",
      "  (24999, 51970)\t1\n",
      "  (24999, 41382)\t1\n",
      "  (24999, 46715)\t1\n",
      "  (24999, 63926)\t1\n",
      "  (24999, 33335)\t1\n",
      "  (24999, 26230)\t1\n",
      "  (24999, 36521)\t1\n",
      "  (24999, 48601)\t1\n",
      "  (24999, 3525)\t1\n",
      "  (24999, 80269)\t1\n",
      "  (24999, 12480)\t1\n",
      "  (24999, 51993)\t1\n",
      "  (24999, 72329)\t1\n",
      "  (24999, 19578)\t1\n"
     ]
    }
   ],
   "source": [
    "#Feature Vectorization (Unigram)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#stop_words parameter: If ‘english’, a built-in stop word list for English is used. There are several known issues with ‘english’ and you should consider an alternative (see Using stop words).\n",
    "#ngram_range parameter: The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted\n",
    "#max_features parameter: Max number of features\n",
    "vectorizer = CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(reviews_train)\n",
    "X_test_counts = vectorizer.transform(reviews_test)\n",
    "\n",
    "print(X_train_counts.shape)\n",
    "print(X_train_counts)\n",
    "#print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1788926)\n",
      "  (0, 1779801)\t1\n",
      "  (0, 1728851)\t2\n",
      "  (0, 1026100)\t1\n",
      "  (0, 85404)\t1\n",
      "  (0, 601879)\t1\n",
      "  (0, 972813)\t1\n",
      "  (0, 299608)\t2\n",
      "  (0, 1611947)\t2\n",
      "  (0, 1268660)\t3\n",
      "  (0, 809617)\t3\n",
      "  (0, 1574956)\t1\n",
      "  (0, 571570)\t1\n",
      "  (0, 627267)\t1\n",
      "  (0, 931363)\t1\n",
      "  (0, 768432)\t1\n",
      "  (0, 1674249)\t1\n",
      "  (0, 1146420)\t1\n",
      "  (0, 968664)\t1\n",
      "  (0, 1247843)\t1\n",
      "  (0, 1476007)\t1\n",
      "  (0, 1452565)\t2\n",
      "  (0, 1384059)\t1\n",
      "  (0, 1677473)\t2\n",
      "  (0, 1552026)\t3\n",
      "  (0, 461569)\t2\n",
      "  :\t:\n",
      "  (24999, 524869)\t1\n",
      "  (24999, 125362)\t1\n",
      "  (24999, 1579413)\t1\n",
      "  (24999, 1087997)\t1\n",
      "  (24999, 1037485)\t1\n",
      "  (24999, 528217)\t1\n",
      "  (24999, 1211676)\t1\n",
      "  (24999, 1276154)\t1\n",
      "  (24999, 701014)\t1\n",
      "  (24999, 667142)\t1\n",
      "  (24999, 125364)\t1\n",
      "  (24999, 1696612)\t1\n",
      "  (24999, 1211677)\t1\n",
      "  (24999, 910885)\t1\n",
      "  (24999, 121673)\t1\n",
      "  (24999, 690998)\t1\n",
      "  (24999, 42680)\t1\n",
      "  (24999, 171599)\t1\n",
      "  (24999, 966393)\t1\n",
      "  (24999, 1085926)\t1\n",
      "  (24999, 361923)\t1\n",
      "  (24999, 620623)\t1\n",
      "  (24999, 1638954)\t1\n",
      "  (24999, 1086124)\t1\n",
      "  (24999, 354342)\t1\n"
     ]
    }
   ],
   "source": [
    "#Feature Vectorization (Bigram)\n",
    "vectorizer_bigram = CountVectorizer(stop_words = stop_words, ngram_range=(1,2), max_features = None)\n",
    "\n",
    "X_train_counts_bigram = vectorizer_bigram.fit_transform(reviews_train)\n",
    "X_test_counts_bigram = vectorizer_bigram.transform(reviews_test)\n",
    "\n",
    "print(X_train_counts_bigram.shape)\n",
    "print(X_train_counts_bigram)\n",
    "#print(vectorizer_bigram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 83709)\n",
      "  (0, 82964)\t0.05221177274727149\n",
      "  (0, 82844)\t0.07972538428518645\n",
      "  (0, 82300)\t0.03271402497608624\n",
      "  (0, 80001)\t0.04402710997524492\n",
      "  (0, 78581)\t0.05695791592330504\n",
      "  (0, 78348)\t0.13524158505920802\n",
      "  (0, 76757)\t0.04010159789938834\n",
      "  (0, 74746)\t0.029104583514764668\n",
      "  (0, 74527)\t0.061070153767845387\n",
      "  (0, 74412)\t0.04741473491377038\n",
      "  (0, 73231)\t0.11324688717515709\n",
      "  (0, 72086)\t0.07724353249348244\n",
      "  (0, 71976)\t0.06766505065739878\n",
      "  (0, 70744)\t0.09436254444676614\n",
      "  (0, 69573)\t0.13685638381842014\n",
      "  (0, 67599)\t0.06700810382774898\n",
      "  (0, 67421)\t0.08142218998376172\n",
      "  (0, 65626)\t0.04834264932275125\n",
      "  (0, 63038)\t0.07028142865923703\n",
      "  (0, 62959)\t0.04712401462116071\n",
      "  (0, 59609)\t0.04767561632456453\n",
      "  (0, 59507)\t0.06501747020756085\n",
      "  (0, 57561)\t0.07093659985164538\n",
      "  (0, 57090)\t0.046901116291481935\n",
      "  (0, 56285)\t0.1218237897686146\n",
      "  :\t:\n",
      "  (24998, 1273)\t0.09800989033177318\n",
      "  (24998, 213)\t0.1025315157384896\n",
      "  (24999, 82448)\t0.1706071270253806\n",
      "  (24999, 80269)\t0.18296777718529145\n",
      "  (24999, 80001)\t0.13042313727711607\n",
      "  (24999, 72789)\t0.12342081113583632\n",
      "  (24999, 72329)\t0.3388400951760983\n",
      "  (24999, 64578)\t0.11841199766124061\n",
      "  (24999, 63926)\t0.1620013440678996\n",
      "  (24999, 57090)\t0.138936912551683\n",
      "  (24999, 51993)\t0.4321014208268224\n",
      "  (24999, 51970)\t0.13585202463978324\n",
      "  (24999, 49954)\t0.1027600839994979\n",
      "  (24999, 49626)\t0.13022669500892775\n",
      "  (24999, 48601)\t0.21803457556162173\n",
      "  (24999, 46715)\t0.16143645964326375\n",
      "  (24999, 41382)\t0.11588141865103764\n",
      "  (24999, 38618)\t0.14835757831656227\n",
      "  (24999, 36521)\t0.1845354967208457\n",
      "  (24999, 33335)\t0.19887251773205614\n",
      "  (24999, 31395)\t0.0886839974214793\n",
      "  (24999, 26230)\t0.14025258556973985\n",
      "  (24999, 19578)\t0.47370285258785655\n",
      "  (24999, 12480)\t0.17464618652376737\n",
      "  (24999, 3525)\t0.18174412941924856\n"
     ]
    }
   ],
   "source": [
    "#Feature Vectorization (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Classifier Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reviews_train\n",
    "X_test = reviews_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train_counts, target, train_size=0.8, test_size = 0.2)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_val.shape)\n",
    "#print(X_val.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Pipeline for Cross Validation\n",
    "\n",
    "A pipeline for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.88024 0.88024 0.88024 0.88024 0.89796 0.89768 0.8974  0.89832 0.88024\n",
      " 0.88024 0.88024 0.88024 0.89796 0.89768 0.8974  0.89832]\n",
      "scores_std [0.00392408 0.00392408 0.00392408 0.00392408 0.00351773 0.0034862\n",
      " 0.00379684 0.00340963 0.00392408 0.00392408 0.00392408 0.00392408\n",
      " 0.00351773 0.0034862  0.00379684 0.00340963]\n",
      "Best score: 0.898\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__max_iter: 5000\n",
      "clf__penalty: 'none'\n",
      "clf__tol: 0.0001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,2), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Tol parameter:Tolerance for stopping criteria\n",
    "#penalty parameter:Used to specify the norm used in the penalization\n",
    "#max_iter parameter: Maximum number of iterations\n",
    "parameters = {'clf__tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "             'clf__penalty': ['l2','none'],\n",
    "             'clf__max_iter': [5000 , 10000]}\n",
    "n_folds = 5\n",
    "\n",
    "LR_GridSearch = GridSearchCV(pipeline, param_grid = parameters, cv=n_folds)\n",
    "LR_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = LR_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = LR_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % LR_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, LR_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 0 ... 1 0 1]\n",
      "Accuracy:  88.604 %\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,2), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(penalty = 'none', max_iter = 5000, tol = 0.0001))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_predLR = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Predicted: \", y_predLR)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_predLR)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.8888  0.88884 0.88884 0.88884 0.87696 0.87632 0.87592 0.87572 0.8888\n",
      " 0.88884 0.88884 0.88884 0.87696 0.87632 0.87592 0.87572]\n",
      "scores_std [0.00217624 0.00217035 0.00217035 0.00217035 0.00317591 0.00400719\n",
      " 0.00438835 0.0042757  0.00217624 0.00217035 0.00217035 0.00217035\n",
      " 0.00317591 0.00400719 0.00438835 0.0042757 ]\n",
      "Best score: 0.889\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__max_iter: 5000\n",
      "clf__penalty: 'l2'\n",
      "clf__tol: 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Tol parameter:Tolerance for stopping criteria\n",
    "#penalty parameter:Used to specify the norm used in the penalization\n",
    "#max_iter parameter: Maximum number of iterations\n",
    "parameters = {'clf__tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "             'clf__penalty': ['l2','none'],\n",
    "             'clf__max_iter': [5000 , 10000]}\n",
    "n_folds = 5\n",
    "\n",
    "LR_GridSearch = GridSearchCV(pipeline, param_grid = parameters, cv=n_folds)\n",
    "LR_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = LR_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = LR_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % LR_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, LR_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 1 ... 0 0 1]\n",
      "Accuracy:  88.096 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(penalty = 'l2', max_iter = 5000, tol = 0.01))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_predLR = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Predicted: \", y_predLR)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_predLR)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Which Features (Words) Were the Most Valuable for Classification as Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most likely indicating a positive review: \n",
      "('refreshing', 1.7175049814884682)\n",
      "('wonderfully', 1.422528422037771)\n",
      "('flawless', 1.3984179262985494)\n",
      "('funniest', 1.3903952602260683)\n",
      "('carrey', 1.3737672265950387)\n",
      "('superb', 1.3370703605562042)\n",
      "('excellent', 1.3369896009500923)\n",
      "('whoopi', 1.2920025417369037)\n",
      "('erotic', 1.2612708532873178)\n",
      "('perfect', 1.2482001813653578)\n",
      "('appreciated', 1.2380654331689525)\n",
      "('highly', 1.2351227424279925)\n",
      "('vengeance', 1.2303834876128503)\n",
      "('rare', 1.221420058662947)\n",
      "('kurosawa', 1.211920500426305)\n",
      "('squirrel', 1.2033936929458637)\n",
      "('hooked', 1.1939963892826)\n",
      "('surprisingly', 1.1890965903955188)\n",
      "('kitty', 1.1757888998076977)\n",
      "('favorite', 1.1753785731595447)\n",
      "\n",
      " Words most likely indicating a negative review: \n",
      "('disappointment', -2.1434870063824376)\n",
      "('worst', -2.1100052264304145)\n",
      "('waste', -2.1001727417208125)\n",
      "('poorly', -1.8327431499331674)\n",
      "('awful', -1.7110023549387137)\n",
      "('fails', -1.5656426308464777)\n",
      "('disappointing', -1.5547261389013962)\n",
      "('avoid', -1.5018792120837416)\n",
      "('unfunny', -1.4968778280418964)\n",
      "('britney', -1.469900087724516)\n",
      "('laughable', -1.4343622886186982)\n",
      "('alright', -1.4022578779485222)\n",
      "('forgettable', -1.3882325686511714)\n",
      "('mess', -1.3760336900758785)\n",
      "('horrible', -1.3662975433859288)\n",
      "('unwatchable', -1.3452609258893973)\n",
      "('boring', -1.3445664434277471)\n",
      "('dreadful', -1.3203527630462375)\n",
      "('baldwin', -1.3183786307231355)\n",
      "('worse', -1.31432445886428)\n"
     ]
    }
   ],
   "source": [
    "clf_LR = LogisticRegression(penalty = 'l2', max_iter = 5000, tol = 0.01)\n",
    "clf_LR.fit(X_train_counts, y_train)\n",
    "pred = clf_LR.predict(X_test_counts)\n",
    "\n",
    "feature_to_coef = {word: coef for word, coef in zip(vectorizer.get_feature_names(), clf_LR.coef_[0])}\n",
    "\n",
    "print(\"Words most likely indicating a positive review: \")\n",
    "for most_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print (most_positive)\n",
    "  \n",
    "print(\"\\n Words most likely indicating a negative review: \")\n",
    "for most_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:20]:\n",
    "    print (most_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most likely indicating a positive review: \n",
      "('excellent', 1.3904501045454358)\n",
      "('perfect', 1.176889254407725)\n",
      "('wonderful', 1.097221774949489)\n",
      "('superb', 1.0786629665769676)\n",
      "('amazing', 1.014681761894561)\n",
      "('favorite', 0.9990117121247385)\n",
      "('must see', 0.9826868317690972)\n",
      "('funniest', 0.9800389023288956)\n",
      "('10 10', 0.9637499218609806)\n",
      "('wonderfully', 0.9188874929486968)\n",
      "('rare', 0.8980345389760819)\n",
      "('enjoyable', 0.8831662342029309)\n",
      "('refreshing', 0.8777194815541556)\n",
      "('brilliant', 0.8775231200083236)\n",
      "('well worth', 0.8585792221178361)\n",
      "('enjoyed', 0.8543388620257607)\n",
      "('fantastic', 0.8445487505698687)\n",
      "('highly', 0.8128121785445597)\n",
      "('loved', 0.8056488353351996)\n",
      "('hilarious', 0.7983441993322362)\n",
      "\n",
      " Words most likely indicating a negative review: \n",
      "('worst', -1.9978069635398459)\n",
      "('awful', -1.6288989479826508)\n",
      "('waste', -1.6010621540565426)\n",
      "('boring', -1.4560925479867468)\n",
      "('disappointment', -1.407918124782598)\n",
      "('poorly', -1.3200912478926778)\n",
      "('dull', -1.2420047097459963)\n",
      "('disappointing', -1.2414543254699235)\n",
      "('worse', -1.2138956950069024)\n",
      "('horrible', -1.192235238886568)\n",
      "('fails', -1.1519529115270761)\n",
      "('terrible', -1.1311250758160234)\n",
      "('save', -1.1278665143264992)\n",
      "('poor', -1.126911358891769)\n",
      "('unfortunately', -1.1252624127494715)\n",
      "('avoid', -1.0716345636616937)\n",
      "('weak', -1.0499985766501827)\n",
      "('mess', -1.018694967956633)\n",
      "('lame', -1.0060298794777294)\n",
      "('annoying', -1.0053286473491487)\n"
     ]
    }
   ],
   "source": [
    "clf_LR = LogisticRegression(penalty = 'l2', max_iter = 5000, tol = 0.01)\n",
    "clf_LR.fit(X_train_counts_bigram, y_train)\n",
    "pred = clf_LR.predict(X_test_counts_bigram)\n",
    "\n",
    "feature_to_coef = {word: coef for word, coef in zip(vectorizer_bigram.get_feature_names(), clf_LR.coef_[0])}\n",
    "\n",
    "print(\"Words most likely indicating a positive review: \")\n",
    "for most_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print (most_positive)\n",
    "  \n",
    "print(\"\\n Words most likely indicating a negative review: \")\n",
    "for most_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:20]:\n",
    "    print (most_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.86408 0.86496 0.86344 0.86096]\n",
      "scores_std [0.00218577 0.00301038 0.00298369 0.00252159]\n",
      "Best score: 0.865\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__alpha: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipelineMNB = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "#alpha parameter: Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing)\n",
    "parameters = {'clf__alpha': [1, 0.5, 0.2, 0.1]}\n",
    "n_folds = 5\n",
    "\n",
    "\n",
    "MNB_GridSearch = GridSearchCV(pipelineMNB, param_grid = parameters, cv=n_folds)\n",
    "MNB_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = MNB_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = MNB_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % MNB_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, MNB_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 1 ... 0 0 0]\n",
      "Accuracy:  82.512 %\n"
     ]
    }
   ],
   "source": [
    "pipelineMNB = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha = 0.5))\n",
    "])\n",
    "\n",
    "pipelineMNB.fit(X_train, y_train)\n",
    "y_predMNB = pipelineMNB.predict(X_test)\n",
    "\n",
    "print(\"Predicted: \", y_predMNB)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_predMNB)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.53756 0.55516 0.59668 0.6054  0.6542  0.64244 0.67712 0.71472 0.64604\n",
      " 0.8028  0.81044 0.81304 0.8504  0.851   0.85096 0.84344 0.84456 0.84464\n",
      " 0.89012 0.89068 0.89032 0.8814  0.88096 0.8812 ]\n",
      "scores_std [0.06226876 0.07351771 0.11496473 0.0693687  0.11526158 0.11890537\n",
      " 0.12176335 0.07459358 0.09064978 0.01504074 0.00612849 0.00346733\n",
      " 0.00498799 0.00528999 0.00548948 0.00321098 0.00358307 0.00265149\n",
      " 0.00228945 0.00315113 0.00248065 0.0026803  0.00215184 0.0015748 ]\n",
      "Best score: 0.891\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__alpha: 0.0001\n",
      "clf__loss: 'hinge'\n",
      "clf__max_iter: 80\n",
      "clf__penalty: 'l2'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipelineSGD = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "#loss parameter:The loss function to be used\n",
    "#penalty parameter:The penalty (aka regularization term) to be used\n",
    "#alpha parameter:Constant that multiplies the regularization term\n",
    "#max_iter parameter:The maximum number of passes over the training data (aka epochs)\n",
    "parameters = {'clf__loss': ['hinge', 'log'],\n",
    "             'clf__penalty': ['l2'],\n",
    "             'clf__alpha': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "             'clf__max_iter': [60, 80, 100]}\n",
    "n_folds = 5\n",
    "\n",
    "\n",
    "SGD_GridSearch = GridSearchCV(pipelineSGD, param_grid = parameters, cv=n_folds)\n",
    "SGD_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = SGD_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = SGD_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % SGD_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, SGD_GridSearch.best_params_[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 0 ... 1 1 1]\n",
      "Accuracy:  88.056 %\n"
     ]
    }
   ],
   "source": [
    "pipelineSGD = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-4, max_iter=80))\n",
    "])\n",
    "\n",
    "pipelineSGD.fit(X_train, y_train)\n",
    "\n",
    "y_predSGD = pipelineSGD.predict(X_test)\n",
    "print(\"Predicted: \", y_predSGD)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_predSGD)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.64208 0.58956 0.71524 0.54756 0.51076 0.68928 0.57996 0.50916 0.72696\n",
      " 0.61656 0.51984 0.73632 0.62512 0.5372  0.7276  0.64596 0.59612 0.71444\n",
      " 0.54736 0.51152 0.68672 0.56228 0.51352 0.71812 0.61328 0.52344 0.72784\n",
      " 0.62428 0.54832 0.72232]\n",
      "scores_std [0.00888648 0.00891058 0.00523129 0.01728602 0.00871725 0.00839771\n",
      " 0.01613414 0.00632253 0.00868691 0.02759896 0.0123699  0.00573495\n",
      " 0.01093881 0.00734956 0.00473793 0.01114587 0.01246281 0.00713683\n",
      " 0.01431721 0.01056152 0.00827681 0.01015843 0.01425348 0.00952605\n",
      " 0.01956552 0.00755608 0.00684503 0.01722491 0.0175009  0.00669758]\n",
      "Best score: 0.736\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__criterion: 'gini'\n",
      "clf__max_depth: 20\n",
      "clf__max_features: None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline_tree = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "#criterion parameter:The function to measure the quality of a split.\n",
    "#max_depth parameter:The maximum depth of the tree. \n",
    "#max_features parameter:The number of features to consider when looking for the best split. If “sqrt”, then max_features=sqrt(n_features). If “log2”, then max_features=log2(n_features).\n",
    "parameters = {'clf__criterion': ['gini', 'entropy'],\n",
    "             'clf__max_depth': [None, 5, 10, 20, 40],\n",
    "             'clf__max_features': ['sqrt', 'log2', None]}\n",
    "n_folds = 5\n",
    "\n",
    "\n",
    "tree_GridSearch = GridSearchCV(pipeline_tree, param_grid = parameters, cv=n_folds)\n",
    "tree_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = tree_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = tree_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % tree_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, tree_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 1 ... 1 0 1]\n",
      "Accuracy:  73.78 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline_tree = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', DecisionTreeClassifier(criterion ='gini', max_depth = 20, max_features = None))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = pipeline_tree.predict(X_test)\n",
    "print(\"Predicted: \", y_pred_tree)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_tree)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.89028 0.89032 0.89032 0.89032 0.89036 0.89028 0.89032 0.89032 0.89028\n",
      " 0.89032 0.89032 0.89032 0.89372 0.8938  0.8938  0.89376 0.89372 0.89384\n",
      " 0.8938  0.8938  0.89408 0.89384 0.8938  0.8938 ]\n",
      "scores_std [0.00261258 0.00292192 0.00281311 0.00281311 0.00303947 0.00281879\n",
      " 0.00281311 0.00281311 0.00286664 0.00281311 0.00281311 0.00281311\n",
      " 0.00106283 0.0010198  0.0010198  0.00099116 0.00106283 0.00106883\n",
      " 0.0010198  0.0010198  0.00108517 0.00106883 0.0010198  0.0010198 ]\n",
      "Best score: 0.894\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__C: 0.5\n",
      "clf__max_iter: 2000\n",
      "clf__penalty: 'l2'\n",
      "clf__tol: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipelineSVM = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "#penalty parameter:Specifies the norm used in the penalization\n",
    "#tol parameter:Tolerance for stopping criteria.\n",
    "#C parameter: Regularization parameter. The strength of the regularization is inversely proportional to C.\n",
    "#max_iter parameter:The maximum number of iterations to be run\n",
    "parameters = {'clf__penalty': ['l2'],\n",
    "             'clf__tol': [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "              'clf__C': [1.0, 0.5],\n",
    "             'clf__max_iter': [1000, 1500, 2000]}\n",
    "n_folds = 5\n",
    "\n",
    "\n",
    "SVM_GridSearch = GridSearchCV(pipelineSVM, param_grid = parameters, cv=n_folds)\n",
    "SVM_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = SVM_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = SVM_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % SVM_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, SVM_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 0 1 ... 0 0 1]\n",
      "Accuracy:  87.532 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipelineSVM = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC(C = 0.5, max_iter = 2000, penalty = 'l2', tol = 0.1))\n",
    "])\n",
    "\n",
    "\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "\n",
    "y_predSVM = pipelineSVM.predict(X_test)\n",
    "print(\"Predicted: \", y_predSVM)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_predSVM)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.72824 0.76388 0.78176 0.7922  0.7962  0.82464 0.83644 0.84184 0.79892\n",
      " 0.82396 0.83032 0.83868]\n",
      "scores_std [0.01028039 0.00997806 0.01042413 0.01077998 0.00930892 0.00906633\n",
      " 0.00596577 0.00494514 0.00610652 0.00625127 0.00623872 0.00408039]\n",
      "Best score: 0.842\n",
      "\n",
      " Best Parameter Values: \n",
      "clf__base_estimator: None\n",
      "clf__learning_rate: 0.5\n",
      "clf__n_estimators: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "pipelineADA = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "#base_estimator parameter: The base estimator from which the boosted ensemble is built.\n",
    "#n_estimators: The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.\n",
    "#learning_rate:Learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "parameters = {'clf__base_estimator': [None],\n",
    "              'clf__n_estimators': [50, 100, 150, 200],\n",
    "             'clf__learning_rate': [0.1, 0.5, 1]}\n",
    "n_folds = 5\n",
    "\n",
    "Ada_GridSearch = GridSearchCV(pipelineADA, param_grid = parameters, cv=n_folds)\n",
    "Ada_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = Ada_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = Ada_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % Ada_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, Ada_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 1 1 ... 1 1 1]\n",
      "Accuracy:  86.064 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "pipelineADA = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AdaBoostClassifier(base_estimator = None, n_estimators = 500, learning_rate = 0.5))\n",
    "])\n",
    "\n",
    "pipelineADA.fit(X_train, y_train)\n",
    "\n",
    "y_pred_Ada = pipelineADA.predict(X_test)\n",
    "print(\"Predicted: \", y_pred_Ada)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_Ada)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipelineForest = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "#n_estimators parameter:The number of trees in the forest\n",
    "#criterion parameter:The function to measure the quality of a split (gini or entropy)\n",
    "#max_depth parameter:The maximum depth of the tree.\n",
    "#max_features parameter:The number of features to consider when looking for the best split. If “sqrt”, then max_features=sqrt(n_features) (same as “auto”). If “log2”, then max_features=log2(n_features). If None, then max_features=n_features.\n",
    "#bootstrap parameter: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.\n",
    "parameters = {'clf__n_estimators': [50, 70, 90],\n",
    "             'clf__criterion': ['gini', 'entropy'],\n",
    "             'clf__max_depth': [None, 10, 20],\n",
    "             'clf__max_features': ['sqrt', 'log2', None],\n",
    "             'clf__bootstrap': [True, False]}\n",
    "n_folds = 5\n",
    "\n",
    "forest_GridSearch = GridSearchCV(pipelineForest, param_grid = parameters, cv=n_folds)\n",
    "forest_GridSearch.fit(X_train, y_train)\n",
    "\n",
    "scores = forest_GridSearch.cv_results_['mean_test_score']\n",
    "scores_std = forest_GridSearch.cv_results_['std_test_score']\n",
    "\n",
    "print('scores:',scores)\n",
    "print('scores_std',scores_std)\n",
    "\n",
    "print(\"Best score: %0.3f\" % forest_GridSearch.best_score_)\n",
    "\n",
    "print(\"\\n Best Parameter Values: \")\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, forest_GridSearch.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 1 1 ... 1 0 1]\n",
      "Accuracy:  85.32 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipelineForest = Pipeline([ \n",
    "    ('vectorizer', CountVectorizer(stop_words = stop_words, ngram_range = (1,1), max_features = None)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators = 120, criterion = 'entropy', max_depth = None, max_features = 'sqrt', bootstrap = False))\n",
    "])\n",
    "\n",
    "pipelineForest.fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = pipelineForest.predict(X_test)\n",
    "print(\"Predicted: \", y_pred_forest)\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_forest)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze which Model is the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  88.096 %\n",
      "Logistic Regression Recall:  88.064 %\n",
      "Logistic Regression Precision:  88.12039705411463 % \n",
      "\n",
      "Decision Tree Accuracy:  73.78 %\n",
      "Decision Tree Recall:  83.072 %\n",
      "Decision Tree Precision:  70.0532955542063 % \n",
      "\n",
      "SVM Accuracy:  87.532 %\n",
      "SVM Recall:  86.504 %\n",
      "SVM Precision:  88.31985624438454 % \n",
      "\n",
      "Adaboost Accuracy:  86.064 %\n",
      "Adaboost Recall:  87.792 %\n",
      "Adaboost Precision:  84.85926384163317 % \n",
      "\n",
      "Random Forest Accuracy:  85.32 %\n",
      "Random Forest Recall:  84.896 %\n",
      "Random Forest Precision:  85.6220751976763 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Accuracy: \", metrics.accuracy_score(y_test, y_predLR)*100, \"%\")\n",
    "print(\"Logistic Regression Recall: \", metrics.recall_score(y_test, y_predLR)*100, \"%\")\n",
    "print(\"Logistic Regression Precision: \", metrics.precision_score(y_test, y_predLR)*100, \"%\", '\\n')\n",
    "\n",
    "print(\"Decision Tree Accuracy: \", metrics.accuracy_score(y_test, y_pred_tree)*100, \"%\")\n",
    "print(\"Decision Tree Recall: \", metrics.recall_score(y_test, y_pred_tree)*100, \"%\")\n",
    "print(\"Decision Tree Precision: \", metrics.precision_score(y_test, y_pred_tree)*100, \"%\", '\\n')\n",
    "\n",
    "print(\"SVM Accuracy: \", metrics.accuracy_score(y_test, y_predSVM)*100, \"%\")\n",
    "print(\"SVM Recall: \", metrics.recall_score(y_test, y_predSVM)*100, \"%\")\n",
    "print(\"SVM Precision: \", metrics.precision_score(y_test, y_predSVM)*100, \"%\", '\\n')\n",
    "\n",
    "print(\"Adaboost Accuracy: \", metrics.accuracy_score(y_test, y_pred_Ada)*100, \"%\")\n",
    "print(\"Adaboost Recall: \", metrics.recall_score(y_test, y_pred_Ada)*100, \"%\")\n",
    "print(\"Adaboost Precision: \", metrics.precision_score(y_test, y_pred_Ada)*100, \"%\", '\\n')\n",
    "\n",
    "print(\"Random Forest Accuracy: \", metrics.accuracy_score(y_test, y_pred_forest)*100, \"%\")\n",
    "print(\"Random Forest Recall: \", metrics.recall_score(y_test, y_pred_forest)*100, \"%\")\n",
    "print(\"Random Forest Precision: \", metrics.precision_score(y_test, y_pred_forest)*100, \"%\", '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
